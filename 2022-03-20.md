# 1
## 대규모 데이터 처리의 어려운점
- 대규모 데이터는 어떤 점이 어려운가?
    - 메모리 내에서 계산할 수 없다.
        - 메모리 내에서 계산하게 된다면 성능이 빠르겠지만, 대규모 데이터들은 너무 많아서 메모리 내에서 계산할 수가 없다. 디스크에 두고 데이터를 검색해야한다.
- 메모리와 디스크의 속도차
    - 디스크는 메모리보다 훨씬 느리다. 10^5 ~ 10^6 정도 차이가 난다.
- 디스크가 늦는 이유
    1. 탐색 속도
        - 디스크는 물리적 구조로 이루어진 장치고 메모리는 전기적인 신호로 동작한다. 물리적인 구조는 한계가 있다.
        - 디스크는 데이터를 읽을 때 헤드의 이동, 디스크의 회전 등의 이유로 탐색 속도가 늦다.
        - 디스크의 느린다는 단점을 OS가 “비슷한 데이터를 한곳에 모아둬서 한번에 많이 읽게한다” 같은 기술로 커버해준다, 그래도 메모리보다 느리다.
    2. 전송 속도
        - 메모리와 디스크 모두  CPU와 버스로 연결되어있다.
        - 탐색한 데이터를 처리하기위해서는 결국엔 CPU로 보내야하는데 이 속도도 메모리가 훨씬 앞선다.
        - 요즘엔 물리적인 SSD가 나와서 탐색 속도는 빨라졌지만, 그래도 메모리에 비해선 훨씬 느리다.

[출처] 대규모 서비스를 지탱하는 기술(강의5)

# 2 
## 대규모 조정의 요소(CPU부하와 I/O부하)
- 규모조정, 확장성
    - 웹 서비스에서 성능을 높이는 일반적인 방법은 **스케일 아웃**이다. 고가의 하드웨어를 사는 스케일업보다 일반적인 성능의 하드웨어를 여러대 나열하는 것이 더 저렴하고 유연성이 크기 때문이다.
- CPU부하와 I/O부하
    - 우리가 서비스를 이용할때 사용되는 애플리케이션 서버는 기본적으로 **CPU부하만 소요**된다.
    - 하지만 서버는 결국 DB의 질의와 결과를 얻어내야하는데 이때는 **I/O부하**가 걸린다.
- CPU부하로 인한 확장, I/O부하로 인한 DB 확장
    - **애플리케이션 서버는 CPU부하만 걸리므로 분산(=스케일 아웃)이 간단하다.** 그 이유는 기본적으로 데이터를 분산해서 갖고 있는 것이 아니고, 어떤 요청이 들어오면 서버들이 동일하게 처리만 하면 되기 때문이다. 따라서 확장을 위해선 동일한 서버의 대수만 늘리면 되는데, 이는 로드밸런서가 해준다.
    - **반면에 I/O부하로 인한 DB서버 분산에는 문제가 있다.** DB를 여러개 확장하면 그 DB들간의 데이터를 어떻게 동기화 할 것인가에 대한 숙제가 생기기 때문이다.
- DB 확장성 확보의 어려움
    - 위에서 설명한 동기화 문제와 더불어 **DB는 디스크를 많이 사용하기때문에 이 또한 성능의 문제**가 될 수 도 있다.
    - 즉, 대규모 환경에서는 I/O 부하를 부담하고 있는 DB서버는 애초에 분산시키기도 어렵고, 디스크 I/O가 많이 발생할 수 있기때문에 더 어려워진다.
    
- 정리
    - CPU 부하의 규모조정은 간단하다
        - 같은 구성의 서버를 늘리고 로드밸런서로 분산
    - I/O 부하의 규모조정은 어렵다
        - DB 동기화와 디스크 접근에 대한 한계

[출처] 대규모 서비스를 지탱하는 기술(강의6)

# 3
## enum의 활용
- enum 이란
    -  우리가 흔히 상수를 정의할 때 final static string 과 같은 방식으로 상수를 정의를합니다. 하지만 이렇게 상수를 정의해서 코딩하는 경우 다양한 문제가 발생됩니다. 
        따라서 이러한 문제점들을 보완하기 위해 자바 1.5버전부터 새롭게 추가된 것이 바로 "Enum" 입니다.
        Enum은 열거형이라고 불리며, 서로 연관된 상수들의 집합을 의미합니다.
        기존에 상수를 정의하는 방법이였던 final static string 과 같이 문자열이나 숫자들을 나타내는 기본자료형의 값을 enum을 이용해서 같은 효과를 낼 수 있습니다.
        
- enum 장점
    - 코드가 단순해지며, 가독성이 좋습니다.
    - 인스턴스 생성과 상속을 방지하여 상수값의 타입안정성이 보장됩니다.
    - enum class를 사용해 새로운 상수들의 타입을 정의함으로 정의한 타입이외의 타입을 가진 데이터값을 컴파일시 체크한다.
    - 키워드 enum을 사용하기 때문에 구현의 의도가 열거임을 분명하게 알 수 있습니다.

- 기본 enum 예제
    - 요구사항
        - 스위치 상수를 만들어라. (ON과 OFF의 상태가 있다)    
  ```
    public enum Switch {
        ON,
        OFF;
    }
    
    ----
    
    public static void main(String[] args) {
        Switch.ON; // 이런식으로 사용 가능. DB에 Switch 데이터를 그대로 넣게되면 ON만 들어감
    }
  ```
  
- enum 활용
    - 요구사항
        - 재고의 개수와 재고의 상태에 따라 상품의 노출, 비노출을 결정하는 컨슈머가 있다.
        - 재고는 판매중, 재고소진, 판매중지의 상태를 갖는다.
        - 판매중일 상태일때는 재고의 개수와 상관없이 상품의 노출이 변경되면 안된다.
        - 재고소진일 상태일때는 재고의 상태가 0개가 아니면 상품의 노출이 ON 되어야 한다. 재고가 0이면 변견되면 안된다.
        - 판매중지일 상태일때는 재고의 개수와 상관없이 삼품의 노출이 OFF가 되어야 한다.
 
    ```
    
    @AllArgsConstructor
    public enum SkuStatus {
        ON_SALE("판매중",
            Collections.EMPTY_LIST
        ),
        PULL_OUT("재고소진",
            Arrays.asList(
                SkuStatuss.Display.Request.of(true)
            )
        ),
        STOP_SALE("판매중지",
            Collections.EMPTY_LIST
        );

        @Getter
        private final String description;
        private final List<Display.Request> displayOnValues;

        private boolean isDisplayPass(final Display.Request request) {
            if (this == ON_SALE) {
                return true;
            }
            
            if (!request.stockZero) {
                return false;
            }

            return true;
        }

        private boolean isDisplayOn(final Display.Request request) {
            return displayOnValues.contains(request);
        }

        public Display getDisplayBy(final Display.Request request) {
            if (isDisplayPass(request)) {
                return Display.PASS;
            }
            if (isDisplayOn(request)) {
                return Display.ON;
            }

            return Display.OFF;
        }


        @AllArgsConstructor
        public enum Display {
            ON("노출"),
            OFF("비노출"),
            PASS("변경없음"),
            NONE(Strings.EMPTY);

            private final String description;

            public boolean isDisplay() {
                return this == ON;
            }

            @AllArgsConstructor
            public static class Request {
                private static final List<Request> ALL_REQUESTS;

                private static final Request ALL_TRUE = new Request(true);
                private static final Request ALL_FALSE = new Request(false);

                static {
                    ALL_REQUESTS = Arrays.asList(ALL_TRUE, ALL_FALSE);
                }

                private final boolean stockZero;

                public static Request of(final boolean stockZero) {
                    return ALL_REQUESTS.stream()
                        .filter(request -> request.stockZero == stockZero)
                        .findFirst()
                        .get();
                }
            }
        }
    }
    
    ------
    
    public static class Sku {
    
        private SkuStatus skuStatus;
        private int stock;

        public SkuStatus.Display getSkuDisplay() {
            return skuStatus.getDisplayBy(SkuStatus.Display.Request.of(stock == 0));
        }
    }
    
    ------
    
    // sns로 컨슈머 사용한다고 예를 들겠음.
    @SqsListener(value = "${sk-status}", deletionPolicy = ON_SUCCESS)
    public externalApiSkuStatus(Sku message) {
        
        ...
        
        SkuStatus.Display display = message.getSkuDisplay(); // 재고의 상태와 개수에 따른 상품의 Display가 정해진다.
        
        // display를 가지고 상품의 노출을 업데이트
        
    }
       
    ```
 [출처] https://limkydev.tistory.com/50

# 4
## KAFKA 
### kafka 란,
- 분산형 스트리밍 플랫폼(A distributed streaming platform)이다. LinkedIn에서 여러 구직 및 채용 정보들을 한곳에서 처리(발행/구독)할 수 있는 플래폼으로 개발이 시작 되었다고 한다.
- (발행/구독: pub-sub은 메시지를 특정 수신자에게 직접적으로 보내주는 시스템이 아니고, 메시지를 받기를 원하는 사람이 해당 토픽(topic)을 구독함으로써 메시지를 읽어 올 수 있다.)

- 카프카의 특징
    - 대용량 실시간 로그처리에 특화되어 설계된 메시징 시스템으로 TPS가 매우 우수
    - 메시지를 메모리에 저장하는 기존 메시징 시스템과는 달리 파일에 저장을 하는데 그로 인해 카프카를 재시작해도 메시지 유실 우려가 감소된다.
<img width="793" alt="kafka기본구조" src="https://user-images.githubusercontent.com/83939644/159114483-5af8a3f2-7041-4558-8987-a5f97167a6d1.png">

```
카프카 클러스터는 여러개의 브로커(서버의개념)를 포함하고있다.
아로헌 카프카 클러스터를 포함하는 주 클러스터가 있으며
프로듀서는 메시지를 나타내며 카프카클러스터에 메시지를 전송을 하며,
컨슈머는 프로듀서로부터 메세지를 카프카클러스터를 통해 받는 주체를 뜻한다.

•producer : 메세지 생산(발행)자.   
•consumer : 메세지 소비자, 하나의 서버   
•consumer group : consumer 들끼리 메세지를 나눠서 가져간다.offset 을 공유하여 중복으로 가져가지 않는다.   
•broker : 카프카 서버   
•zookeeper : 카프카 서버 (+클러스터) 상태를 관리   
•cluster : 브로커들의 묶음   
•topic : 메세지 종류, 데이터베이스의 table정도의 개념으로 생각 카프카에 저장되는 데이터를 구분하기위해 토픽이라는 이름을 사용한다.   
•partitions : topic 이 나눠지는 단위 하나의 파티션에 대해 데이터의 순서를 보장한다. 만약 토픽에 대해 모든데이터의 순서를 보장받고 싶다면 파티션의 수를 1로 생성하면 된다. 파티션은 각각의 파티션에 대해서만 순서를 보장하고 만약 파티션의 숫작 많아진다면 프로듀서가 보낸 순서대로 메시지를 가져올 수 없다?   
•Log : 1개의 메세지   
•offset : 파티션 내에서 각 메시지가 가지는 unique id   
```
# 5
## @Async
- @Async Annotation은 Spring에서 제공하는 Thread Pool을 활용하는 비동기 메소드 지원 Annotation이다.

- @Async 작동
    - 비동기로 작동하길 원하는 method 위에 @Async Annotation을 붙여주면 사용할 수 있다. 
    - 스프링 부트의 경우 @EnableAsync 선언을 하여 Async사용 선언을 하며, 전자정부및 스프링의 경우 web.xml의 설정을통해서 가능.
```
public class GillogAsync {

    @Async
    public void asyncMethod(final String message) throws Exception {
        ....
    }
}
```

- @Async 주의사항
    - private method는 사용 불가, public method만 사용 가능
    - self-invocation(자가 호출) 불가, 즉 inner method는 사용 불가
    - QueueCapacity 초과 요청에 대한 비동기 method 호출시 방어 코드 작성

![async 원리](https://user-images.githubusercontent.com/83939644/159114489-dd85980d-7ea5-4be3-9a35-6123ef3f0a9f.png)

```
sync의 동작은 AOP가 적용되어 Spring Context에서 등록된 Bean Object의 method가 호출 될 시에,
Spring이 확인할 수 있고 @Async가 적용된 method의 경우 Spring이 method를 가로채    
다른 Thread에서 실행 시켜주는 동작 방식이다.   
이 때문에 Spring이 해당 @Async method를 가로챈 후, 다른 Class에서 호출이 가능해야 하므로,   
private method는 사용할 수 없는 것이다.

또한 Spring Context에 등록된 Bean의 method의 호출이어야 Proxy 적용이 가능하므로,
inner method의 호출은 Proxy 영향을 받지 않기에 self-invocation이 불가능하다.

적용 예시 ) 회원가입시, 메일발송 등 다른 서버와 연결을할시 여러사용자에게 발송을 할경우 리턴타입을 가지지않아도 
될 경우 사용 하면 10명의 사용자기준 10초 에서 2초로 단축.
```
# 6
## 대규모 데이터를 다루기 위한 기초지식
- 프로그램을 작성할 때의 요령
    1. 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
        - 디스크 seek(탐색) 횟수에 따라 성능에 많은 영향을 준다. 그래서 메모리에서 처리를 마쳐야한다.
        - **즉, 메모리를 활용해서 디스크 seek횟수를 최소화**한다.
    2. 알고리즘, 데이터 구조 활용
        - 1억건의 데이터를 선형검색 하는것보다 이분탐색같은 O(logN)알고리즘을 사용하는 것이 훨씬 성능향상에 도움을 준다.
    3. 데이터 압축과 검색 기술
        - 데이터 압축
            - **압축해서 데이터량을 줄여야한다.** 데이터를 압축하면 디스크의 seek횟수도 최소화된다.
            - **데이터를 압축하면 메모리 캐싱도 쉬워진다.** 데이터가 크면 메모리에서 넘치거나, 디스크에 저장해도 읽는데 시간이 걸린다.
        - 검색 기술
            - 확장성면에서 DB에만 맡겨서 해결할 수 없을때, **특정 용도에 특화된 검색 엔진을 애플리케이션에서 이용하면 속도 기대에 도움을 준다.**
- 프로그램 개발에 근간이 되는 기초
    1. OS캐시
    2. 분산을 고려한 RDBMS 운용
    3. 알고리즘과 데이터 구조
- Load Average 다음은 CPU사용률과 I/O 대기율(linux)
    - Load Average는 처리를 실행하려고 해도 실행할 수 없어서 대기하고 있는 프로세스 수이다. 하지만 이것만으로는 CPU부하인지, I/O부하인지 알 수가 없다.
    - 그래서 sar 명령어로 CPU사용률이 높은지, I/O대기율이 높은지 확인해야한다.
    - 만약 멀티 코어 cpu에서 확인하고 싶다면 sar -P 라는 명령어를 써야한다. 그러면 cpu별로 확인이 가능하다.
    - 알아야할 점은 멀티 cpu여도 디스크가 한개라면, I/O 부하는 다른 cpu로 분산되지 않는다. 하지만 cpu 부하는 다른 cpu로 분산된다.

[출처] 대규모 서비스를 지탱하는 기술(강의7)

# 7

# 8

# 9
